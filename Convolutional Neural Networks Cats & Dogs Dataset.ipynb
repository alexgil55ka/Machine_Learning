{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# Initial deep neural network set-up from \n",
    "# GeÃÅron, A. 2017. Hands-On Machine Learning with Scikit-Learn \n",
    "#    & TensorFlow: Concepts, Tools, and Techniques to Build \n",
    "#    Intelligent Systems. Sebastopol, Calif.: O'Reilly. \n",
    "#    [ISBN-13 978-1-491-96229-9] \n",
    "#    Source code available at https://github.com/ageron/handson-ml\n",
    "#    See file 10_introduction_to_artificial_neural_networks.ipynb \n",
    "#    Revised from MNIST to Cats and Dogs to begin Assignment 7\n",
    "#    #CatsDogs# comment lines show additions/revisions for Cats and Dogs\n",
    "\n",
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports for our work\n",
    "import os \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "RANDOM_SEED = 9999\n",
    "\n",
    "# To make output stable across runs\n",
    "def reset_graph(seed= RANDOM_SEED):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CatsDogs# Old dimensions from MNIST no loger apply\n",
    "#CatsDogs# height = 28\n",
    "#CatsDogs# width = 28\n",
    "height = 64\n",
    "width = 64  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CatsDogs# \n",
    "# Documentation on npy binary format for saving numpy arrays for later use\n",
    "#     https://towardsdatascience.com/\n",
    "#             why-you-should-start-using-npy-file-more-often-df2a13cc0161\n",
    "# Under the working directory, data files are in directory cats_dogs_64_128 \n",
    "# Read in cats and dogs grayscale 64x64 files to create training data\n",
    "cats_1000_64_64_1 = np.load('cats-dogs-jump-start-v002/cats_dogs_64-128/cats_1000_64_64_1.npy')\n",
    "dogs_1000_64_64_1 = np.load('cats-dogs-jump-start-v002/cats_dogs_64-128/dogs_1000_64_64_1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt  # for display of images\n",
    "def show_grayscale_image(image):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examine first cat and first dog grayscale images\n",
    "show_grayscale_image(cats_1000_64_64_1[0,:,:,0])\n",
    "show_grayscale_image(dogs_1000_64_64_1[0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rework the Data and Split into Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work the data for cats and dogs numpy arrays \n",
    "# These numpy arrays were generated in previous data prep work\n",
    "# Stack the numpy arrays for the inputs\n",
    "X_cat_dog = np.concatenate((cats_1000_64_64_1, dogs_1000_64_64_1), axis = 0) \n",
    "X_cat_dog = X_cat_dog.reshape(-1,width*height) # note coversion to 4096 inputs\n",
    "\n",
    "# Scikit Learn for min-max scaling of the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(np.array([0., 255.]).reshape(-1,1))\n",
    "X_cat_dog_min_max = scaler.transform(X_cat_dog)\n",
    "\n",
    "# Define the labels to be used 1000 cats = 0 1000 dogs = 1\n",
    "y_cat_dog = np.concatenate((np.zeros((1000), dtype = np.int32), \n",
    "                      np.ones((1000), dtype = np.int32)), axis = 0)\n",
    "\n",
    "# Scikit Learn for random splitting of the data  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Random splitting of the data in to training (80%) and test (20%)  \n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X_cat_dog_min_max, y_cat_dog, test_size=0.20, \n",
    "                     random_state = RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 300 and 100 nodes for layers 1 and 2 as used with MNIST from Geron\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "channels = 1  # When working with color images use channels = 3\n",
    "n_inputs = height * width\n",
    "\n",
    "#CatsDogs# Has two output values # MNIST had ten digits n_outputs = 10  \n",
    "n_outputs = 2  # binary classification for Cats and Dogs, 1 output node 0/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DNN Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "# dnn... Deep neural network model from Geron Chapter 10\n",
    "# Note that this model makes no use of the fact that we have\n",
    "# pixel data arranged in rows and columns\n",
    "# So a 64x64 matrix of raster values becomes a vector of 4096 input variables\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\",\n",
    "                           activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                           activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))    \n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.64 Test accuracy: 0.5075\n",
      "1 Train accuracy: 0.63 Test accuracy: 0.51\n",
      "2 Train accuracy: 0.64 Test accuracy: 0.52\n",
      "3 Train accuracy: 0.65 Test accuracy: 0.52\n",
      "4 Train accuracy: 0.64 Test accuracy: 0.515\n",
      "5 Train accuracy: 0.68 Test accuracy: 0.515\n",
      "6 Train accuracy: 0.67 Test accuracy: 0.53\n",
      "7 Train accuracy: 0.69 Test accuracy: 0.5275\n",
      "8 Train accuracy: 0.69 Test accuracy: 0.535\n",
      "9 Train accuracy: 0.69 Test accuracy: 0.5275\n",
      "10 Train accuracy: 0.71 Test accuracy: 0.5275\n",
      "11 Train accuracy: 0.73 Test accuracy: 0.54\n",
      "12 Train accuracy: 0.68 Test accuracy: 0.525\n",
      "13 Train accuracy: 0.68 Test accuracy: 0.515\n",
      "14 Train accuracy: 0.72 Test accuracy: 0.5325\n",
      "15 Train accuracy: 0.69 Test accuracy: 0.515\n",
      "16 Train accuracy: 0.7 Test accuracy: 0.52\n",
      "17 Train accuracy: 0.68 Test accuracy: 0.5125\n",
      "18 Train accuracy: 0.78 Test accuracy: 0.55\n",
      "19 Train accuracy: 0.79 Test accuracy: 0.56\n",
      "20 Train accuracy: 0.82 Test accuracy: 0.59\n",
      "21 Train accuracy: 0.81 Test accuracy: 0.54\n",
      "22 Train accuracy: 0.68 Test accuracy: 0.525\n",
      "23 Train accuracy: 0.68 Test accuracy: 0.515\n",
      "24 Train accuracy: 0.68 Test accuracy: 0.515\n",
      "25 Train accuracy: 0.81 Test accuracy: 0.5525\n",
      "26 Train accuracy: 0.77 Test accuracy: 0.56\n",
      "27 Train accuracy: 0.82 Test accuracy: 0.565\n",
      "28 Train accuracy: 0.72 Test accuracy: 0.5175\n",
      "29 Train accuracy: 0.74 Test accuracy: 0.56\n",
      "30 Train accuracy: 0.83 Test accuracy: 0.57\n",
      "31 Train accuracy: 0.72 Test accuracy: 0.515\n",
      "32 Train accuracy: 0.68 Test accuracy: 0.51\n",
      "33 Train accuracy: 0.85 Test accuracy: 0.5525\n",
      "34 Train accuracy: 0.69 Test accuracy: 0.5125\n",
      "35 Train accuracy: 0.84 Test accuracy: 0.5825\n",
      "36 Train accuracy: 0.85 Test accuracy: 0.6\n",
      "37 Train accuracy: 0.87 Test accuracy: 0.58\n",
      "38 Train accuracy: 0.75 Test accuracy: 0.525\n",
      "39 Train accuracy: 0.77 Test accuracy: 0.55\n",
      "40 Train accuracy: 0.83 Test accuracy: 0.585\n",
      "41 Train accuracy: 0.89 Test accuracy: 0.585\n",
      "42 Train accuracy: 0.84 Test accuracy: 0.5275\n",
      "43 Train accuracy: 0.72 Test accuracy: 0.53\n",
      "44 Train accuracy: 0.69 Test accuracy: 0.515\n",
      "45 Train accuracy: 0.74 Test accuracy: 0.535\n",
      "46 Train accuracy: 0.69 Test accuracy: 0.515\n",
      "47 Train accuracy: 0.76 Test accuracy: 0.5575\n",
      "48 Train accuracy: 0.88 Test accuracy: 0.585\n",
      "49 Train accuracy: 0.85 Test accuracy: 0.58\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()    \n",
    "\n",
    "n_epochs = 50\n",
    "batch_size = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(y_train.shape[0] // batch_size):\n",
    "            X_batch = X_train[iteration*batch_size:(iteration + 1)*batch_size,:]\n",
    "            y_batch = y_train[iteration*batch_size:(iteration + 1)*batch_size]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "\n",
    "        save_path = saver.save(sess, \"./my_catdog_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0811 22:35:26.117274 20640 deprecation.py:323] From <ipython-input-22-2592acbce4da>:28: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W0811 22:35:26.120302 20640 deprecation.py:506] From C:\\Users\\Himalaya\\Anaconda3\\envs\\hello-tf\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0811 22:35:27.924288 20640 deprecation.py:323] From <ipython-input-22-2592acbce4da>:37: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    }
   ],
   "source": [
    "height = 64\n",
    "width = 64 \n",
    "channels = 1  # When working with color images use channels = 3\n",
    "n_inputs = height * width\n",
    "n_outputs = 2\n",
    "conv1_fmaps = 32\n",
    "conv1_ksize = 3\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "conv2_fmaps = 64\n",
    "conv2_ksize = 3\n",
    "conv2_stride = 2\n",
    "conv2_pad = \"SAME\"\n",
    "#conv2_dropout_rate = 0.25\n",
    "\n",
    "pool3_fmaps = conv2_fmaps\n",
    "n_fc1 = 72\n",
    "fc1_dropout_rate = 0.5\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "    \n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "conv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv2\")\n",
    "with tf.name_scope(\"pool3\"):\n",
    "    pool3 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 16 * 16])\n",
    "\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool3_flat, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = .001)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X_cat_dog_min_max, y_cat_dog, test_size=0.20, \n",
    "                     random_state = RANDOM_SEED)\n",
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Shape:0' shape=(1,) dtype=int32>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate .001\n",
    "### Tested with 20, 25, and 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "1 Train accuracy: 0.6 Test accuracy: 0.495\n",
      "2 Train accuracy: 0.67 Test accuracy: 0.53\n",
      "3 Train accuracy: 0.66 Test accuracy: 0.5975\n",
      "4 Train accuracy: 0.72 Test accuracy: 0.59\n",
      "5 Train accuracy: 0.76 Test accuracy: 0.6125\n",
      "6 Train accuracy: 0.73 Test accuracy: 0.6125\n",
      "7 Train accuracy: 0.8 Test accuracy: 0.6275\n",
      "8 Train accuracy: 0.86 Test accuracy: 0.6275\n",
      "9 Train accuracy: 0.92 Test accuracy: 0.625\n",
      "10 Train accuracy: 0.92 Test accuracy: 0.635\n",
      "11 Train accuracy: 0.94 Test accuracy: 0.6225\n",
      "12 Train accuracy: 0.98 Test accuracy: 0.6425\n",
      "13 Train accuracy: 1.0 Test accuracy: 0.63\n",
      "14 Train accuracy: 1.0 Test accuracy: 0.635\n",
      "15 Train accuracy: 0.9 Test accuracy: 0.6325\n",
      "16 Train accuracy: 0.99 Test accuracy: 0.62\n",
      "17 Train accuracy: 1.0 Test accuracy: 0.6375\n",
      "18 Train accuracy: 0.99 Test accuracy: 0.6075\n",
      "19 Train accuracy: 1.0 Test accuracy: 0.6325\n",
      "20 Train accuracy: 1.0 Test accuracy: 0.62\n",
      "21 Train accuracy: 1.0 Test accuracy: 0.6225\n",
      "22 Train accuracy: 1.0 Test accuracy: 0.62\n",
      "23 Train accuracy: 1.0 Test accuracy: 0.6175\n",
      "24 Train accuracy: 1.0 Test accuracy: 0.615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "118.01953792572021"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()    \n",
    "\n",
    "n_epochs = 25\n",
    "batch_size = 100\n",
    "start = time.time()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "                \n",
    "        for iteration in range(y_train.shape[0] // batch_size):\n",
    "            X_batch = X_train[iteration*batch_size:(iteration + 1)*batch_size,:]\n",
    "            y_batch = y_train[iteration*batch_size:(iteration + 1)*batch_size]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "        \n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "        \n",
    "end = time.time()\n",
    "Runtime = end-start\n",
    "Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 64\n",
    "width = 64 \n",
    "channels = 1  # When working with color images use channels = 3\n",
    "n_inputs = height * width\n",
    "n_outputs = 2\n",
    "conv1_fmaps = 32\n",
    "conv1_ksize = 3\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "conv2_fmaps = 64\n",
    "conv2_ksize = 3\n",
    "conv2_stride = 2\n",
    "conv2_pad = \"SAME\"\n",
    "#conv2_dropout_rate = 0.25\n",
    "\n",
    "pool3_fmaps = conv2_fmaps\n",
    "n_fc1 = 72\n",
    "fc1_dropout_rate = 0.5\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "    \n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "conv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv2\")\n",
    "with tf.name_scope(\"pool3\"):\n",
    "    pool3 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 16 * 16])\n",
    "\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool3_flat, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = .1)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X_cat_dog_min_max, y_cat_dog, test_size=0.20, \n",
    "                     random_state = RANDOM_SEED)\n",
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "1 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "2 Train accuracy: 0.41 Test accuracy: 0.52\n",
      "3 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "4 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "5 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "6 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "7 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "8 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "9 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "10 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "11 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "12 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "13 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "14 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "15 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "16 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "17 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "18 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "19 Train accuracy: 0.59 Test accuracy: 0.48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "261.69815611839294"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()    \n",
    "\n",
    "n_epochs = 20\n",
    "batch_size = 100\n",
    "start = time.time()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):                \n",
    "        for iteration in range(y_train.shape[0] // batch_size):\n",
    "            X_batch = X_train[iteration*batch_size:(iteration + 1)*batch_size,:]\n",
    "            y_batch = y_train[iteration*batch_size:(iteration + 1)*batch_size]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "        \n",
    "end = time.time()\n",
    "Runtime = end-start\n",
    "Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " With .1 Learning Rate there is is no improvement in learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 64\n",
    "width = 64 \n",
    "channels = 1  # When working with color images use channels = 3\n",
    "n_inputs = height * width\n",
    "n_outputs = 2\n",
    "conv1_fmaps = 32\n",
    "conv1_ksize = 3\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "conv2_fmaps = 64\n",
    "conv2_ksize = 3\n",
    "conv2_stride = 2\n",
    "conv2_pad = \"SAME\"\n",
    "#conv2_dropout_rate = 0.25\n",
    "\n",
    "pool3_fmaps = conv2_fmaps\n",
    "n_fc1 = 72\n",
    "fc1_dropout_rate = 0.5\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "    \n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "conv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv2\")\n",
    "with tf.name_scope(\"pool3\"):\n",
    "    pool3 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 16 * 16])\n",
    "\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool3_flat, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = .0001)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X_cat_dog_min_max, y_cat_dog, test_size=0.20, \n",
    "                     random_state = RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate .0001\n",
    "### Tested with 20, 25, and 30 epochs\n",
    "### Also tested batch sizes 50, 100 and 200, with no increase in performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.64 Test accuracy: 0.505\n",
      "1 Train accuracy: 0.66 Test accuracy: 0.5425\n",
      "2 Train accuracy: 0.7 Test accuracy: 0.585\n",
      "3 Train accuracy: 0.72 Test accuracy: 0.59\n",
      "4 Train accuracy: 0.74 Test accuracy: 0.5925\n",
      "5 Train accuracy: 0.76 Test accuracy: 0.6125\n",
      "6 Train accuracy: 0.76 Test accuracy: 0.6325\n",
      "7 Train accuracy: 0.82 Test accuracy: 0.63\n",
      "8 Train accuracy: 0.86 Test accuracy: 0.625\n",
      "9 Train accuracy: 0.88 Test accuracy: 0.6225\n",
      "10 Train accuracy: 0.88 Test accuracy: 0.63\n",
      "11 Train accuracy: 0.92 Test accuracy: 0.6375\n",
      "12 Train accuracy: 0.94 Test accuracy: 0.635\n",
      "13 Train accuracy: 0.94 Test accuracy: 0.6325\n",
      "14 Train accuracy: 0.92 Test accuracy: 0.6325\n",
      "15 Train accuracy: 0.92 Test accuracy: 0.63\n",
      "16 Train accuracy: 0.92 Test accuracy: 0.6325\n",
      "17 Train accuracy: 0.94 Test accuracy: 0.6275\n",
      "18 Train accuracy: 0.94 Test accuracy: 0.635\n",
      "19 Train accuracy: 0.94 Test accuracy: 0.64\n",
      "20 Train accuracy: 0.94 Test accuracy: 0.6425\n",
      "21 Train accuracy: 0.96 Test accuracy: 0.6425\n",
      "22 Train accuracy: 0.96 Test accuracy: 0.6375\n",
      "23 Train accuracy: 0.96 Test accuracy: 0.64\n",
      "24 Train accuracy: 0.96 Test accuracy: 0.645\n",
      "25 Train accuracy: 0.96 Test accuracy: 0.645\n",
      "26 Train accuracy: 0.96 Test accuracy: 0.6425\n",
      "27 Train accuracy: 0.96 Test accuracy: 0.6425\n",
      "28 Train accuracy: 0.96 Test accuracy: 0.64\n",
      "29 Train accuracy: 0.98 Test accuracy: 0.6475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "393.7229838371277"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()    \n",
    "\n",
    "n_epochs = 30\n",
    "batch_size = 50\n",
    "iteration = 0\n",
    "\n",
    "best_loss_val = np.infty\n",
    "check_interval = 500\n",
    "checks_since_last_progress = 0\n",
    "max_checks_without_progress = 20\n",
    "best_model_params = None \n",
    "\n",
    "start = time.time()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(y_train.shape[0] // batch_size):\n",
    "            X_batch = X_train[iteration*batch_size:(iteration + 1)*batch_size,:]\n",
    "            y_batch = y_train[iteration*batch_size:(iteration + 1)*batch_size]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "\n",
    "end = time.time()\n",
    "Runtime = end-start\n",
    "Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
